{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. 读取训练数据 与 测试数据\n",
    "def read_data(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    # data构成了train和test的全部的数据\n",
    "    data = pd.concat((train_df.iloc[:, 1:-1], test_df.iloc[:, 1:]))\n",
    "    print(\"data.shape=\", data.shape)\n",
    "    # 删除缺失值超过1/3的特征, 仅以train_df\n",
    "    missing = data.isnull().sum()\n",
    "    missing = missing[missing > data.shape[0] // 3]\n",
    "    mov_f = list(dict(missing).keys())\n",
    "    data = data.drop(labels=mov_f, axis=1)\n",
    "    print(\"after delete nan features, data.shape=\", data.shape)\n",
    "    # 对numeric对象进行均值归一化\n",
    "    numeric = [num for num in data.columns if data.dtypes[num] != 'object']\n",
    "    data[numeric] = data[numeric].apply(lambda x: (x-x.mean())/x.std())\n",
    "    data[numeric] = data[numeric].fillna(0)\n",
    "    # 对category特征进行onehot编码, 这将大大增加特征数量\n",
    "    data = pd.get_dummies(data, dummy_na=True)\n",
    "    print(\"after one-hot operation, data.shape=\", data.shape)\n",
    "    # 转为tensor后返回\n",
    "    train_size = train_df.shape[0]\n",
    "    train_features = torch.tensor(data[:train_size].values, dtype=torch.float32)\n",
    "    test_features = torch.tensor(data[train_size:].values, dtype=torch.float32)\n",
    "    train_labels = torch.tensor(train_df[\"SalePrice\"].values.reshape(-1, 1), dtype=torch.float32)\n",
    "    test_ID = torch.tensor(test_df[\"Id\"].values.reshape(-1, 1), dtype=torch.int32)\n",
    "    return train_features, train_labels, test_features, test_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b26b68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape= (2919, 79)\n",
      "after delete nan features, data.shape= (2919, 74)\n",
      "after one-hot operation, data.shape= (2919, 308)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_ID= read_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf7eab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1460, 308]), torch.Size([1460, 1]), torch.Size([1459, 308]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cb6b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型采用基本的线性模型\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import math\n",
    "# 定义和初始化模型\n",
    "input_size = train_features.shape[1]\n",
    "output_size = 1\n",
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(input_size, output_size))\n",
    "    delta = math.sqrt(2/(input_size+output_size))\n",
    "    def init_param(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.normal_(m.weight, mean=0, std=delta)\n",
    "    model.apply(init_param)\n",
    "    return model\n",
    "model = get_model()\n",
    "# 数据加载器\n",
    "batch_size = 100\n",
    "train_iter = data.DataLoader(data.TensorDataset(train_features, train_labels), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76346eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in epoch 0, loss = 484838912.000000\n",
      "in epoch 500, loss = 481690816.000000\n",
      "in epoch 1000, loss = 481189056.000000\n",
      "in epoch 1500, loss = 477411840.000000\n",
      "in epoch 2000, loss = 475435008.000000\n",
      "in epoch 2500, loss = 476512960.000000\n",
      "in epoch 3000, loss = 472008128.000000\n",
      "in epoch 3500, loss = 470398144.000000\n",
      "in epoch 4000, loss = 468623712.000000\n",
      "in epoch 4500, loss = 467889952.000000\n"
     ]
    }
   ],
   "source": [
    "# 损失函数和优化函数\n",
    "loss = nn.MSELoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "# 训练过程\n",
    "epoch_num = 5000\n",
    "for epoch in range(epoch_num):\n",
    "    for X, y in train_iter:\n",
    "        l = loss(model(X), y)\n",
    "        optim.zero_grad()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "    if epoch % 500 == 0:\n",
    "        val = loss(model(train_features), train_labels)\n",
    "        print(f\"in epoch {epoch}, loss = {val:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "874d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = model(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5057102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int32'),\n",
       "      Id      SalePrice\n",
       " 0  1461  109414.078125\n",
       " 1  1462  147857.984375\n",
       " 2  1463  182682.906250\n",
       " 3  1464  192471.359375\n",
       " 4  1465  207182.656250)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prdict = torch.concat([test_ID, test_labels], dim=1)\n",
    "test_prdict = test_prdict.detach().numpy()\n",
    "test_prdict = pd.DataFrame(columns=[\"Id\", \"SalePrice\"], data=test_prdict)\n",
    "test_prdict[\"Id\"] = test_prdict[\"Id\"].astype(int)\n",
    "test_prdict[\"Id\"].dtype, test_prdict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbf5ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prdict.to_csv(\"../output/linear_sgd_001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3099fa",
   "metadata": {},
   "source": [
    "以上实际上使用的技巧就是很基本的，唯一的trick在于直接舍弃了一部分无关的feature, 在模型基本结构和损失函数以及优化算法上并没有什么特别的，在训练时也是采取基本的小批量随机梯度下降算法，采取jiao'xikaggle给出的结论是2817/3984，score=0.18530\n",
    "使用RMSE评分.\n",
    "我看到, 在教程中, 对数据的预处理是：缺失值视为特征的一部分，统统归一化、one-hot编码，也就是在特征选取上并没有什么特别的\n",
    "在模型选择上，基本结构是线性模型\n",
    "在损失函数上，加入了RMSE评估\n",
    "在训练法则上采取了K-折交叉验证方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06214902",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
