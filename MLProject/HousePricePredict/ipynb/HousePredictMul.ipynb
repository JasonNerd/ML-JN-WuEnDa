{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f265302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "def filter_missing(cols, data, rate):\n",
    "    data = data.drop(columns=cols, axis=1)\n",
    "    missing = data.isnull().sum()\n",
    "    missing = missing[missing>int(data.shape[0]*rate)]\n",
    "    data = data.drop(columns=dict(missing).keys(), axis=1)\n",
    "    return data\n",
    "\n",
    "def data_preprocess(train_data, test_data, rate=1, pca=False, pca_dim=100):\n",
    "    train_labels = train_data[\"SalePrice\"]\n",
    "    # 剔除不需要的列, 例如Id, SalePrice以及Nan值过多的列\n",
    "    train_features = filter_missing([\"Id\", \"SalePrice\"], train_data, rate)\n",
    "    test_features = filter_missing([\"Id\"], test_data, rate)\n",
    "    # 拼接起来统一处理, 包括数值特征均值归一化, 0补充Nan值, 分类特征one-hot编码\n",
    "    all_features = pd.concat([train_features, test_features], axis=0)\n",
    "    numeric = [f for f in all_features.columns if all_features.dtypes[f] != 'object']\n",
    "    all_features[numeric] = all_features[numeric].apply(lambda x: (x-x.mean())/x.std())\n",
    "    all_features[numeric] = all_features[numeric].fillna(0)\n",
    "    all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "    train_size = train_data.shape[0]\n",
    "    # 进行PCA降维, 可选\n",
    "    feature = all_features.values\n",
    "    if(pca):\n",
    "        feature, floss = k_pca(feature, pca_dim)\n",
    "        print(f\"feature loss is {floss:.5f}\")\n",
    "    train_X = torch.tensor(feature[:train_size, :], dtype=torch.float32)\n",
    "    test_X = torch.tensor(feature[train_size:, :], dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_labels.values, dtype=torch.float32)\n",
    "    return train_X, train_y, test_X\n",
    "\n",
    "def k_pca(X, k):\n",
    "    X = (X-X.mean())/X.std()\n",
    "    X = np.matrix(X)\n",
    "    Sigma = X.T*X/X.shape[0]\n",
    "    U, S, V = np.linalg.svd(Sigma)\n",
    "    new_f = X*np.matrix(U[:, :k])\n",
    "    f_loss = float(1-S[:k].sum()/S[:].sum())\n",
    "    return new_f, f_loss\n",
    "\n",
    "def rmsle(y_hat, y):\n",
    "    inner = torch.pow((torch.log(y_hat+1)-torch.log(y+1)), 2).sum()/len(y)\n",
    "    return math.sqrt(inner)\n",
    "\n",
    "# 以后初始化就固定这个模式xv_init+apply\n",
    "def get_model(n_in, n_out):\n",
    "    model = nn.Sequential(nn.Linear(n_in, n_out))\n",
    "    def xv_init(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            n_in = m.weight.data.shape[1]\n",
    "            n_out = m.weight.data.shape[0]\n",
    "            std = math.sqrt(2/(n_in+n_out))\n",
    "            nn.init.normal_(m.weight, std=std)\n",
    "    model.apply(xv_init)\n",
    "    return model\n",
    "\n",
    "# MSELoss\n",
    "def get_loss():\n",
    "    return nn.MSELoss()\n",
    "\n",
    "# optim的使用Adam(相对于SGD的优化版), 默认L2惩罚\n",
    "def get_optim(param, lr=0.001, punish=0):\n",
    "    return torch.optim.Adam(param, lr=lr, weight_decay=punish)\n",
    "\n",
    "def shuffle(X, y):\n",
    "    y = y.reshape(-1, 1)\n",
    "    data = torch.concat([X, y], dim=1)\n",
    "    data = data[torch.randperm(data.size(0))] # 按行打乱\n",
    "    return data[:, :-1], data[:, -1]\n",
    "\n",
    "def split(X, y, i, K=10):\n",
    "    \"\"\"X[m, d], y[m], 将X, y分成K块, 第i块作为valid, 其余的作为train集\"\"\"\n",
    "    y = y.reshape(-1, 1)\n",
    "    data = torch.concat([X, y], dim=1)\n",
    "    chunks = torch.chunk(data, K)\n",
    "    valid_ = chunks[i]\n",
    "    train_chunk_list = [chunks[j] for j in range(K) if j!= i]\n",
    "    train_ = torch.concat(train_chunk_list, dim=0)\n",
    "    return train_[:, :-1], train_[:, -1], valid_[:, :-1], valid_[:, -1]\n",
    "\n",
    "def train(train_features, train_labels, lr=0.001, punish=0, m=10, K=10, batch_size=100):\n",
    "    features_num = train_features.shape[1]\n",
    "    model = get_model(features_num, 1)\n",
    "    loss = get_loss()\n",
    "    optim = get_optim(model.parameters(), lr=lr, punish=punish)\n",
    "    val_rmsle, val_rmse = [], []\n",
    "    # 进行m次k折训练\n",
    "    for i in range(m):\n",
    "        # 对 feature 和 label 打乱, 注意对应不变\n",
    "        trf, trl = shuffle(train_features, train_labels)\n",
    "        # 使用chunk()函数\n",
    "        for j in range(K):\n",
    "            train_X, train_y, val_X, val_y = split(trf, trl, j, K)\n",
    "            train_y = train_y.reshape(-1,1)\n",
    "            val_y = val_y.reshape(-1,1)\n",
    "            # 构造train_dataset, 进行小批量随机梯度下降训练\n",
    "            train_dataset = data.TensorDataset(train_X, train_y)\n",
    "            train_iter = data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "            for X, y in train_iter:\n",
    "                l = loss(model(X), y)\n",
    "                optim.zero_grad()\n",
    "                l.backward()\n",
    "                optim.step()\n",
    "            # 计算验证集的rmsle损失\n",
    "            val_rmsle.append(float(rmsle(model(val_X), val_y)))\n",
    "            val_rmse.append(float(loss(model(val_X), val_y)))\n",
    "        if i%10 == 0:\n",
    "            print(f\"第{i+1}次{K}折训练后, 验证集rmsle = {val_rmsle[-1]:.5f}\")\n",
    "    return model, val_rmsle, val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cacd0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1460, 308]) torch.Size([1460]) torch.Size([1459, 308])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(False), tensor(False))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据预处理参数\n",
    "rate = 0.3 # 丢弃缺失值数量比例超过rate的特征\n",
    "pca = False # 是否进行PCA算法降维\n",
    "pca_dim=250 # 降低的维数\n",
    "# 读取和预处理数据\n",
    "train_X, train_y, test_X = data_preprocess(\n",
    "    train_data, \n",
    "    test_data, \n",
    "    rate=rate,\n",
    "    pca=pca,\n",
    "    pca_dim=pca_dim\n",
    ")\n",
    "print(train_X.shape, train_y.shape, test_X.shape)\n",
    "torch.isnan(train_X).any(), torch.isinf(train_X).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3b9b5297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次12折训练后, 验证集rmsle = 4.26949\n",
      "第11次12折训练后, 验证集rmsle = 1.92701\n",
      "第21次12折训练后, 验证集rmsle = 1.26815\n",
      "第31次12折训练后, 验证集rmsle = 0.92468\n",
      "第41次12折训练后, 验证集rmsle = 0.71285\n",
      "第51次12折训练后, 验证集rmsle = 0.47799\n",
      "第61次12折训练后, 验证集rmsle = 0.34223\n",
      "第71次12折训练后, 验证集rmsle = 0.27649\n",
      "第81次12折训练后, 验证集rmsle = 0.19938\n",
      "第91次12折训练后, 验证集rmsle = 0.16316\n",
      "第101次12折训练后, 验证集rmsle = 0.19451\n",
      "第111次12折训练后, 验证集rmsle = 0.13861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.26569747071597"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练参数\n",
    "lr = 0.75  # Adam优化函数学习率\n",
    "K = 12    # K-折交叉验证的K值\n",
    "m = 120   # 进行K-折交叉验证的次数\n",
    "batch_size = 200  # 小批量梯度下降的批量大小\n",
    "# 训练模型\n",
    "model, val_rmsle, val_rmse = train(\n",
    "    train_X, \n",
    "    train_y, \n",
    "    lr=lr, \n",
    "    K=K, \n",
    "    m=m, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "float(rmsle(model(train_X), train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "841c756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型和实验结果\n",
    "# 进行预测\n",
    "import time\n",
    "t = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n",
    "test_predict = model(test_X).detach()\n",
    "test_Ids = torch.tensor(test_data[\"Id\"].values, dtype=int)\n",
    "test_Ids = test_Ids.reshape(-1, 1)\n",
    "submmision = torch.concat([test_Ids, test_predict], dim=1).numpy()\n",
    "submmision = pd.DataFrame(submmision, columns=[\"Id\", \"SalePrice\"])\n",
    "submmision[\"Id\"] = submmision[\"Id\"].astype(int)\n",
    "submmision.to_csv(f\"../output/{t}.csv\", index=False)\n",
    "model_name =  f\"../model/dim{pca_dim}rate{rate}_lr{lr}_K{K}_m{m}_bs{batch_size}\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45da9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
