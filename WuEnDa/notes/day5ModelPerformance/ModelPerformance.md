# 应用机器学习的建议(Advice for Applying Machine Learning)  
&emsp;本部分主要讨论如何评判模型的性能以及在新样本上模型预测值与实际值相差较大时应当如何去改进等等问题。    

## 下一步做什么？
&emsp;在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？  
1. 获取更多的训练样本；这通常是困难的，很多时候并非增加数据量就可以解决问题  
2. 尝试去掉一些特征；仔细挑选需要去掉的特征以防止过拟合，由于没有合适的准则，因此不一定凑效  
3. 尝试发现更多的特征；从更多的角度看待这一问题  
4. 尝试多项式特征；对于已有的特征，增加其多项式表达  
5. 增加正则化系数$\lambda$的大小  
6. 减小正则化系数$\lambda$的大小  

## Evaluate your hypothesis
&emsp;在房价预测的示例中，我们通过作图来直观的感受了过拟合与欠拟合的问题与原因。然而，大多数情况下，由于特征的复杂性，我们无法作出图像，因此需要一种数据化的形式去评估我们的假设模型.<br> 
&emsp;<font color=#A0A>将数据集划分为两个部分，即训练集和测试集。</font>例如，可以将数据划70%为Trainning set and 30% for test.注意数据划分应当均匀，一个做法是对原数据进行shuffle.另外，针对划分方法，可以是直接一刀划为两部分，依据不同划法，进行多次训练，称之为**留出法(hold-out)** 得到的结果可以使用算术平均；也可以将数据集划分为k个大小近似的互斥子集，每次使用k-1个子集进行训练，剩下一个用于验证，因而可以进行k次训练，由于子集划分也具有任意性，因而可以进行m组，称之为**k折交叉验证(k-fold cross validation)**.<br> 
&emsp;<font color=#A0A>将数据集划分为三个部分，即训练集、交叉验证集和测试集。</font>具体做法是：
1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出**交叉验证误差**（代价函数的值）
3. 选取代价函数值最小的模型
4. 用步骤3中选出的模型对测试集计算得出**推广误差**（代价函数的值）

## Bias and Variance(偏差与方差)
&emsp;偏差和方差是描述模型拟合程度的度量，先给出结论，设数据集为$\bold{x}$，当$bias^2(\bold{x})$也即偏差过高时表示欠拟合(underfit)，当$var(\bold{x})$也即方差过高时表示过拟合(overfit).如图所示：
<div align=center><img src="http://www.ai-start.com/ml2014/images/20c6b0ba8375ca496b7557def6c00324.jpg" width=80%></div>

我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析:  
<div align=center><img src="http://www.ai-start.com/ml2014/images/bca6906add60245bbc24d71e22f8b836.png" width=80%></div>

如图所示，横轴表示多项式特征的最高次数，随着幂次的增大，模型在训练集上的拟合程度越来越高，表现为训练误差不断减小，而交叉验证集误差则呈对勾状，表现为一开始误差较大随后不断下降至一个最低点随后又开始不断上升。可以得出，当训练集误差和交叉验证集误差均比较大时，模型欠拟合，偏差高了，需要更多的特征输入，单纯增加训练集大小效果很可能效果不大。而当训练集误差比较小但交叉验证集误差较大时，此时模型过拟合，方差高了，需要提高正则化系数或者减小多项式特征的幂次。

关于偏差与方差的含义或者定义，从西瓜书上了解到：**方差**是指在大小相同的不同训练集上预测值与预测期望值差的平方的期望：
<div align=center><img src="https://files.mdnice.com/user/35698/04bf40ee-4c4d-4dc3-bd44-58e6ba2f4485.png" width=60%></div>
期望输出与真实标记的差别称为偏差：
<div align=center><img src="https://files.mdnice.com/user/35698/fa356837-0176-4aef-8ab4-0c894d850976.png" width=50%></div>
偏差度量了期望输出与真实结果的偏离程度，即刻画了学习算法本身的拟合能力，方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响（此外还有噪声，她=它表达了在当前任务上所有算法能达到的期望泛化误差下界，即刻画了学习问题本身的难度）

### 正则化和偏差/方差
我们选择一系列的想要测试的$\lambda$值，通常是0-10之间的呈现2倍关系的值（如$0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10$：共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。
选择的方法为：
1. 使用训练集训练出12个不同程度正则化的模型
2. 用12个模型分别对交叉验证集计算的出交叉验证误差
3. 选择得出交叉验证误差最小的模型
4. 运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上

### 学习曲线
将数据一行一行的加入到训练集，绘制训练误差和交叉验证集误差随训练集大小m的曲线，此即为学习曲线。一开始，由于数据量较少，模型曲线可以完全通过训练样本点，训练误差较小，但验证集误差较大，随着样本数据的增大，训练误差增大而验证集误差减小，最后他们应当稳定在一个平台。
如何利用学习曲线识别高偏差/欠拟合：作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：
<div align=center><img src="http://www.ai-start.com/ml2014/images/4a5099b9f4b6aac5785cb0ad05289335.jpg" width=80%></div>
也就是说在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。 如何利用学习曲线识别高方差/过拟合：假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。
<div align=center><img src="http://www.ai-start.com/ml2014/images/2977243994d8d28d5ff300680988ec34.jpg" width=80%></div>
也就是说在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。

### 决定下一步做什么
1. 获取更多的训练样本$\leftarrow$高方差/过拟合/训练集误差较小但验证集误差较大
2. 尝试去掉一些特征$\leftarrow$高方差/过拟合/训练集误差较小但验证集误差较大
3. 尝试发现更多的特征$\leftarrow$高偏差/欠拟合/训练集误差和验证集误差都较大
4. 尝试多项式特征$\leftarrow$高偏差/欠拟合/训练集误差和验证集误差都较大
5. 增加正则化系数$\lambda$的大小$\leftarrow$高方差/过拟合/训练集误差较小但验证集误差较大
6. 减小正则化系数$\lambda$的大小$\leftarrow$高偏差/欠拟合/训练集误差和验证集误差都较大
* 使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。 通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。

## 机器学习系统的设计(Machine Learning System Design)
 构建一个学习算法的推荐方法为：
 1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法
 2. 绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择
 3. 进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势
> 以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。 思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。 例如记录下错误拼写出现了多少次，异常的邮件路由情况出现了多少次等等，然后从出现次数最多的情况开始着手优化。 误差分析并不总能帮助我们判断应该采取怎样的行动。有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。 在我们的垃圾邮件分类器例子中，对于“我们是否应该将discount/discounts/discounted/discounting处理成同一个词？”如果这样做可以改善我们算法，我们会采用一些截词软件

### 类偏斜的误差度量(Error Metrics for Skewed Classes)
&emsp;例如癌症的检测，假定是一个二分类问题，即患癌症或者不患癌症，此时一般而言，是健康人的可能性远大于患病的可能性，例如健康者占比99.5%，两个类别占比极度不平衡，称为类偏斜(skewed class)。那么有这样一个分类器，他总是预测为健康，那么他的错误率也只有0.5%，但显然这个预测器不能称之为一个好的预测器，因为它无法检测出癌症患者。因此错误率并不总是很好的刻画预测器的好坏。<br>
&emsp;这里对其进行细化，例如，在预测出的癌症患者(预测为阳性)中有多大比例确实患上了癌症(真阳性, True Positive)，这一比例称为准确率(***precision***)或者**查准率**，要尽可能的准确判断出哪些人确实患病，也即预测器的策略应尽可能的严格，尽可能地保证被判断阳性的人确实患病，尽可能避把正常人划分为患者。<br>
&emsp;另一方面，我们还关心在所有确实患病的人中有多大比例的人是被预测器预测出来了的