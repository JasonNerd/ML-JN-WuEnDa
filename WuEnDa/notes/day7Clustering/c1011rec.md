# 聚类分析
&emsp;&emsp;发现数据内部的结构并进行划分，是无监督学习算法中的一种
聚类划分的应用：
![](./image/2022-10-11-16-40-37.png)
## K-means algorithm
1. 随机选定K(K=2)个聚类中心(cluster centroid),将点分成K类, 依据是离谁进就选谁
![](./image/2022-10-11-16-46-28.png)
2. 接着对于这两个簇，分别计算其中心，作为新的聚类中心
   ![](./image/2022-10-11-16-49-34.png)
3. 重复上述步骤 簇分配、移动聚类中心
4. 直到算法聚合，即中心不再移动
   ![](./image/2022-10-11-16-51-55.png)
K-means for not well seperated data
![](./image/2022-10-11-16-59-00.png)

## Clustering Optimization Objective
K-means算法的优化目标是什么，所有样本点到所在聚类的中心距离的平方和的均值。
![](./image/2022-10-11-20-58-42.png)

## 随机初始化
如何进行随机初始化
![](./image/2022-10-11-21-08-00.png)
![](./image/2022-10-11-21-08-57.png)
如何避免局部最优？
![](./image/2022-10-11-21-11-34.png)
--- 多次随机初始化
## 选择聚类的数量
在没有可视化的图形下，你应该如何选择？
1. elbow method
   ![](./image/2022-10-11-21-19-22.png)
2. 依据需求确定
   ![](./image/2022-10-11-21-21-03.png)

# Dimensionality Reduction-无监督学习的又一个例子
例如：数据压缩(data compressing)，直观而言它帮助我们压缩了数据，使其占用较少的内存空间，另一方面使我们能够对学习算法进行加速

## 什么是降维
高度冗余的特征
![](./image/2022-10-11-21-31-28.png)
![](./image/2022-10-11-21-34-14.png)
![](./image/2022-10-11-21-37-17.png)

## 降维可用于数据可视化
![](./image/2022-10-11-21-41-26.png)
不是用50维，而是尝试使用2维的例如
![](./image/2022-10-11-21-42-44.png)
![](./image/2022-10-11-21-47-58.png)

## Principle Components Algorithm(PCA)主成分分析算法
特征规范化、均值归一化后，进行投影
![](./image/2022-10-12-10-17-56.png)
PCA不是Linear Regression
![](./image/2022-10-12-10-20-28.png)
![](./image/2022-10-12-10-20-43.png)

## PCA算法步骤
1. 数据预处理
   ![](./image/2022-10-12-10-31-46.png)

2. 构造协方差矩阵，进行奇异值分解
   ![](./image/2022-10-12-10-48-16.png)

3. 得到压缩矩阵，进行空间映射
   ![](./image/2022-10-12-10-52-31.png)
   ![](./image/2022-10-12-10-58-53.png)

## 如何选择K
Principle Components Number

# 线性代数知识补充
## 特征值与特征向量

## 二次型与正定矩阵


 