{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e142b70",
   "metadata": {},
   "source": [
    "## 过拟合与欠拟合现象\n",
    "以线性回归模型为基础，拟合目标是$$y = 5 + 1.2x - 3.4\\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\text{ where }\n",
    "\\epsilon \\sim \\mathcal{N}(0, 0.1^2).$$，实验通过变化不同的迭代次数以及最高幂次来调整模型复杂度，数据集可以自行生成，注意区分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02baf79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 20),\n",
       " array([ 1.00000000e+00, -4.10563942e-01,  1.68562751e-01, -6.92057875e-02,\n",
       "         2.84134010e-02, -1.16655179e-02,  4.78944102e-03, -1.96637179e-03,\n",
       "         8.07321354e-04, -3.31457038e-04,  1.36084308e-04, -5.58713101e-05,\n",
       "         2.29387453e-05, -9.41782171e-06,  3.86661801e-06, -1.58749393e-06,\n",
       "         6.51767768e-07, -2.67592344e-07,  1.09863768e-07, -4.51061017e-08]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成模拟数据，训练集100条，验证集100条\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "max_degree = 20 # 多项式最高幂次\n",
    "n_train, n_test = 100, 100\n",
    "w_true = np.zeros(max_degree)\n",
    "w_true[0:4] = np.array([5, 1.2, -3.4, 5.6])\n",
    "# x: 200行1列, 目前仅1个特征x1: x\n",
    "x1 = np.random.normal(size=(n_train+n_test, 1))\n",
    "# 从x1生成其他多项式特征, 包括 x0: 1, x2: (x^2/2)等等\n",
    "np.random.shuffle(x1)\n",
    "X = np.power(x1, np.arange(max_degree).reshape(1, -1))\n",
    "X.shape, X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb060df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20]),\n",
       " torch.Size([100, 20]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 20]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里采用阶乘来scale各个特征\n",
    "for i in range(max_degree):\n",
    "    X[:, i] /= math.gamma(i+1) # gamma(i) = (i+1)!\n",
    "# 生成标签, 添加噪声\n",
    "y = np.dot(X, w_true)\n",
    "y += np.random.normal(scale=0.1, size=y.shape)\n",
    "X_train, y_train, X_val, y_val = X[:n_train, :], y[:n_train], X[n_train:, :], y[n_train:]\n",
    "w_true, X_train, y_train, X_val, y_val = [torch.tensor(i, dtype=torch.float32) for i in [w_true, X_train, y_train, X_val, y_val]]\n",
    "w_true.shape, X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee4dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data\n",
    "# 进行训练\n",
    "def load_data(X, y, batchsize, is_train=True):\n",
    "    dataset = data.TensorDataset(X, y)\n",
    "    return data.DataLoader(dataset, shuffle=is_train, batch_size=batchsize)\n",
    "\n",
    "def train(X_train, y_train, X_val, y_val, num_epoch=400):\n",
    "    loss = nn.MSELoss()\n",
    "    input_size = X_train.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(input_size, 1, bias=False))\n",
    "    trainer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # 设置batch_size, 构造batch_iter\n",
    "    train_iter = load_data(X_train, y_train, batchsize=X_train.shape[0])\n",
    "    # 进行训练\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(num_epoch):\n",
    "        for X, y in train_iter:\n",
    "            l = loss(model(X), y)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        with torch.no_grad():\n",
    "            train_loss.append(loss(model(X_train, y_train)))\n",
    "            val_loss.append(loss(model(X_val, y_val)))\n",
    "    return train_loss, val_loss, model[0].weight.data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def lossPlot(train_loss, val_loss):\n",
    "    plt.plot(range(len(train_loss)), train_loss)\n",
    "    plt.plot(range(len(val_loss)), val_loss)    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c930c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrrai\\.conda\\envs\\MachineLearning\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m w\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 正常情况\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m demostrate()\n",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m, in \u001b[0;36mdemostrate\u001b[1;34m(dim, num_epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdemostrate\u001b[39m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m):\n\u001b[0;32m      2\u001b[0m     _train, _val \u001b[38;5;241m=\u001b[39m X_train[:, :dim], X_val[:, :dim]\n\u001b[1;32m----> 3\u001b[0m     tl, vl, w \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     lossPlot(tl, vl)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m w\n",
      "Cell \u001b[1;32mIn [11], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X_train, y_train, X_val, y_val, num_epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[0;32m     20\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(model(X), y)\n\u001b[1;32m---> 21\u001b[0m     \u001b[43moptim\u001b[49m\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     22\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "def demostrate(dim=3, num_epoch=400):\n",
    "    _train, _val = X_train[:, :dim], X_val[:, :dim]\n",
    "    tl, vl, w = train(_train, y_train, _val, y_val, num_epoch=num_epoch)\n",
    "    lossPlot(tl, vl)\n",
    "    return w\n",
    "# 正常情况\n",
    "demostrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e4832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b98cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e7be1a",
   "metadata": {},
   "source": [
    "#### Dataset+DataLoader--创建和读取自己的数据集\n",
    "`from torch.utils.data import Dataset, DataLoader`\n",
    "[Pytorch（五）入门：DataLoader 和 Dataset](https://blog.csdn.net/zw__chen/article/details/82806900)\n",
    "1. Dataset: (deal_dataset = TensorDataset(x_data, y_data))\n",
    "\n",
    "2. DataLoader: DataLoader是一个比较重要的类，它为我们提供的常用操作有：batch_size(每个batch的大小), shuffle(是否进行shuffle操作), num_workers(加载数据的时候使用几个子进程)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4268513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
