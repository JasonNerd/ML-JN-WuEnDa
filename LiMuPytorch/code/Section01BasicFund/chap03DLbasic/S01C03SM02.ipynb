{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855dd078",
   "metadata": {},
   "source": [
    "[PyTorch之torchvision.transforms详解](https://blog.csdn.net/qq_37555071/article/details/107532319)\n",
    "正如其名所见，transforms是一个用于对图片进行变换的工具包，例如裁剪、缩放、垂直翻转、水平翻转等等，这些操作具有单独的其详细的定义(见链接博客)，而如果需要对图像进行一系列的操作也即操作组合，可以使用Compose()传入的是一个操作列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952440d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1, 28, 28]), torch.Size([256]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## 1. 导入数据\n",
    "trans = transforms.ToTensor() # 转为张量\n",
    "minist_train = FashionMNIST(root=\"../../data\", train=True, transform=trans)\n",
    "minist_test = FashionMNIST(root=\"../../data\", train=False, transform=trans)\n",
    "## 这是小批量读取\n",
    "batch_size = 256\n",
    "train_iter = DataLoader(minist_train, batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = DataLoader(minist_test, batch_size, shuffle=False, num_workers=4)\n",
    "## 测试数据读取是否成功\n",
    "X0, y0 = next(iter(train_iter))\n",
    "X0.shape, y0.shape  # 说明每一个batch包含的是256张图片及其标记，每个图片大小为28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3158ed32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0606, 0.1267])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 此处为实验楼\n",
    "X0r01 = X0.reshape(batch_size, -1)[0:2, :]\n",
    "W0r01 = torch.normal(0, 0.1, size=(784, 10))\n",
    "b0r01 = torch.normal(0, 0.01, size=(1, 10))\n",
    "XW0r01 = torch.matmul(X0r01, W0r01)\n",
    "expXWb = torch.exp(XW0r01+b0r01)\n",
    "eXWbsum = expXWb.sum(dim=1, keepdim=True)\n",
    "pr = expXWb/eXWbsum\n",
    "lby0r01 = torch.tensor([3, 4])\n",
    "pr[[0,1],lby0r01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5c4896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 42.36957\n",
      "train loss = 41.88358\n",
      "train loss = 35.38435\n",
      "train loss = 50.34916\n",
      "train loss = 45.52011\n",
      "train loss = 51.93243\n",
      "train loss = 48.97696\n",
      "train loss = 44.46736\n",
      "train loss = 39.56340\n",
      "train loss = 35.18392\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 28*28\n",
    "num_outputs = 10\n",
    "W = torch.normal(0, 0.1, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "## W:784x10, X:256x1x28x28, b: 1x10, y 1x256\n",
    "## 2. 编写假设函数softmax X --> h(X)\n",
    "## (XW+b)[256x10], 对于每一行求exp/sum(exp)\n",
    "def softmax(X):\n",
    "    # 256x784, 注意最后一个batch可能不是256\n",
    "    expXWb = torch.exp(torch.matmul(X.reshape(-1, num_inputs), W)+b)\n",
    "    sumXWb = expXWb.sum(dim=1, keepdim=True)\n",
    "    return expXWb / sumXWb\n",
    "## 3. 编写损失函数\n",
    "def lossCrossEntropy(y_hat, y):\n",
    "    lCEbatch = -torch.log(y_hat[range(len(y)), y])\n",
    "    return lCEbatch.sum()\n",
    "## 4. 编写优化函数\n",
    "def gradientDescent(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "## 5. 进行训练\n",
    "epoch_num = 10\n",
    "lr = 0.1\n",
    "for epoch in range(epoch_num):\n",
    "    for X, y in train_iter:\n",
    "        l = lossCrossEntropy(softmax(X), y)\n",
    "        l.backward()\n",
    "        gradientDescent([W, b], lr, batch_size)\n",
    "    print(f\"train loss = {float(l):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd5271e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8319), 10000, tensor(0.8319))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算在测试集上的精度\n",
    "def cmpY(y_hat, y):\n",
    "    return (y == y_hat.argmax(dim=1)).sum()\n",
    "acc_cnt = 0\n",
    "sam_tot = 0\n",
    "for X, y in test_iter:\n",
    "    acc_cnt += cmpY(softmax(X), y)\n",
    "    sam_tot += len(y)\n",
    "acc_cnt, sam_tot, acc_cnt/sam_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
