{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950563dc",
   "metadata": {},
   "source": [
    "# 自定义层\n",
    "这里的意思是计算上的自定义, 而不是用现有的进行搭建, 不是搭积木, 而是创建新的积木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537b8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3352e",
   "metadata": {},
   "source": [
    "`CenteredLayer`: 它从输入中减去均值, 不接受任何参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4e586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "   (1): CenteredLayer()\n",
       " ),\n",
       " tensor(0., grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, X):\n",
    "        return X-X.mean()\n",
    "\n",
    "net = nn.Sequential(nn.Linear(3, 6), CenteredLayer())\n",
    "iX = torch.randn(4, 3)\n",
    "io = net(iX)\n",
    "net, io.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51456b6",
   "metadata": {},
   "source": [
    "---\n",
    "一个带参数的层, 例如实现一个MyLinear层, 它接受n_in, n_out, bias作为参数, 设有权重weight和bias项(if bias==true ), 具有与nn.Linear相同的行为."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a90e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12.8676],\n",
       "         [-3.5359],\n",
       "         [-4.9836]], grad_fn=<AddBackward0>),\n",
       " Sequential(\n",
       "   (0): MyLinearA()\n",
       "   (1): MyLinearA()\n",
       " ),\n",
       " OrderedDict())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinearA(nn.Module):\n",
    "    def __init__(self, n_in, n_out, bias=True):\n",
    "        super().__init__()\n",
    "        self.hav_bias = bias\n",
    "        self.weight = torch.randn(n_out, n_in, requires_grad=True)\n",
    "        if self.hav_bias:\n",
    "            self.bias = torch.zeros(n_out, requires_grad=True)\n",
    "    def forward(self, X):\n",
    "        Z = torch.matmul(X, self.weight.T)\n",
    "        if self.hav_bias:\n",
    "            Z = Z + self.bias\n",
    "        return Z\n",
    "net = nn.Sequential(MyLinearA(4, 32), MyLinearA(32, 1))\n",
    "net(torch.randn(3, 4)), net, net.state_dict()\n",
    "# 可以看出应该是有些问题的, state_dict获取不到参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cfb81",
   "metadata": {},
   "source": [
    "以下来自参考代码, 可见需要转换类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f12f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 2.4367, 0.0000, 2.7845],\n",
       "         [0.0000, 2.2957, 1.3112, 0.0000],\n",
       "         [0.4345, 3.5540, 0.0000, 1.0051]], grad_fn=<ReluBackward0>),\n",
       " MyLinear(),\n",
       " OrderedDict([('weight',\n",
       "               tensor([[-2.4772, -0.9873, -0.1902, -0.8379],\n",
       "                       [ 1.2272, -1.5311,  0.6536, -1.3510],\n",
       "                       [ 0.3239, -0.5081, -0.8020,  0.7834],\n",
       "                       [-0.0946,  0.0701, -0.8087,  0.9963],\n",
       "                       [-1.6395,  0.6347, -0.8426,  0.7625],\n",
       "                       [ 0.5313,  0.7384,  0.8902,  1.1225],\n",
       "                       [-0.1281,  0.8938, -0.2132, -0.5563],\n",
       "                       [ 0.1858,  1.1956, -0.2290, -2.4159]])),\n",
       "              ('bias', tensor([-0.5148,  1.0647, -0.2149,  0.5073]))]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, i_, o_):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(i_, o_))\n",
    "        self.bias = nn.Parameter(torch.randn(o_,))\n",
    "    def forward(self, X):\n",
    "        return F.relu(torch.matmul(X, self.weight)+self.bias)\n",
    "net = MyLinear(8, 4)\n",
    "net(torch.randn(3, 8)), net, net.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
