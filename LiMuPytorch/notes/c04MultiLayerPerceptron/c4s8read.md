# 关于机器学习系统工作的一些建议

## 1. 模型参数的初始化很重要
&emsp;&emsp;初始化方案的选择在神经网络学习中起着举足轻重的作用， 它对**保持数值稳定性**至关重要。 此外，这些初始化方案的选择可以与非线性激活函数的选择有趣的结合在一起。 我们选择哪个函数以及如何初始化参数可以决定优化算法收敛的速度有多快。 糟糕选择可能会导致我们在训练时遇到**梯度爆炸**或**梯度消失**。 
### 梯度爆炸与梯度消失
&emsp;&emsp;例如激活函数sigmoid函数的输入很大或是很小时，它的梯度都会消失。 此外，当反向传播通过许多层时，除非我们在刚刚好的地方， 这些地方sigmoid函数的输入接近于零，否则整个乘积的梯度可能会消失。 当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。 事实上，这个问题曾经困扰着深度网络的训练。 因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。
&emsp;&emsp;最初，矩阵  可能具有各种各样的特征值。 他们可能很小，也可能很大； 他们的乘积可能非常大，也可能非常小。不稳定梯度带来的风险不止在于数值表示； 不稳定梯度也威胁到我们优化算法的稳定性。 我们可能面临一些问题。 要么是梯度爆炸（gradient exploding）问题： 参数更新过大，破坏了模型的稳定收敛； 要么是梯度消失（gradient vanishing）问题： 参数更新过小，在每次更新时几乎不会移动，导致模型无法学习
### 参数的对称性
&emsp;&emsp;可以见到，目前的神经网络各层之间是全相连的，因而对于某一层的所有节点而言，在结构上他们是等价的，而如果此时参数也都相同，那么他们就总会同步的变化，使得网络失效，因此需要随机初始化，另外暂退法可以从结构上打破对称性。
### Xavier初始化

让我们看看某些没有非线性的全连接层输出（例如，隐藏变量）的尺度分布。 对于该层输入及其相关权重，输出由下式给出
$$o_{i} = \sum_{j=1}^{n_\mathrm{in}} w_{ij} x_j.$$
权重都是从同一分布中独立抽取的。 此外，让我们假设该分布具有零均值和方差。 请注意，这并不意味着分布必须是高斯的，只是均值和方差需要存在。 现在，让我们假设层的输入也具有零均值和方差， 并且它们独立于并且彼此独立。 在这种情况下，我们可以按如下方式计算的平均值和方差：
$$\begin{split}\begin{aligned}
    E[o_i] & = \sum_{j=1}^{n_\mathrm{in}} E[w_{ij} x_j] \\&= \sum_{j=1}^{n_\mathrm{in}} E[w_{ij}] E[x_j] \\&= 0, \\
    \mathrm{Var}[o_i] & = E[o_i^2] - (E[o_i])^2 \\
        & = \sum_{j=1}^{n_\mathrm{in}} E[w^2_{ij} x^2_j] - 0 \\
        & = \sum_{j=1}^{n_\mathrm{in}} E[w^2_{ij}] E[x^2_j] \\
        & = n_\mathrm{in} \sigma^2 \gamma^2.
\end{aligned}\end{split}$$
保持方差不变的一种方法是设置。 现在考虑反向传播过程，我们面临着类似的问题，尽管梯度是从更靠近输出的层传播的。 使用与前向传播相同的推断，我们可以看到，除非， 否则梯度的方差可能会增大，其中是该层的输出的数量。 这使得我们进退两难：我们不可能同时满足这两个条件。 相反，我们只需满足：
$\begin{aligned}
\frac{1}{2} (n_\mathrm{in} + n_\mathrm{out}) \sigma^2 = 1 \text{ 或等价于 }
\sigma = \sqrt{\frac{2}{n_\mathrm{in} + n_\mathrm{out}}}.
\end{aligned}$
这就是现在标准且实用的Xavier初始化的基础， 它以其提出者 [Glorot & Bengio, 2010] 第一作者的名字命名。 通常，Xavier初始化从均值为零，方差$\sigma^2 = \frac{2}{n_\mathrm{in} + n_\mathrm{out}}$的高斯分布中采样权重。

## 2. 数据的采集
### 数据分布偏移
数据分布不再和训练时候的数据集分布相同，而是发生了变化。许多失败的机器学习部署（即实际应用）都可以追究到这种方式。 有时，根据测试集的精度衡量，模型表现得非常出色。 但是**当数据分布突然改变时，模型在部署中会出现灾难性的失败**。 更隐蔽的是，有时**模型的部署本身就是扰乱数据分布的催化剂**。  假设我们训练了一个贷款申请人违约风险模型，用来预测谁将偿还贷款或违约。 这个模型发现申请人的鞋子与违约风险相关（穿牛津鞋申请人会偿还，穿运动鞋申请人会违约）。 此后，这个模型可能倾向于向所有穿着牛津鞋的申请人发放贷款，并拒绝所有穿着运动鞋的申请人。

这种情况可能会带来灾难性的后果。 首先，一旦模型开始根据鞋类做出决定，顾客就会理解并改变他们的行为。 不久，所有的申请者都会穿牛津鞋，而信用度却没有相应的提高。 总而言之，机器学习的许多应用中都存在类似的问题： 通过将基于模型的决策引入环境，我们可能会破坏模型。

### 分布偏移的类型

1. 协变量偏移
虽然**输入的分布可能随时间而改变， 但标签函数（即条件分布）没有改变。 统计学家称之为协变量偏移（covariate shift）**， 因为这个问题是由于协变量（特征）分布的变化而产生的。 
考虑一下区分猫和狗的问题，训练数据如图：
![](https://zh-v2.d2l.ai/_images/cat-dog-train.svg)
在测试时，我们被要求对这些图像进行分类。
![](https://zh-v2.d2l.ai/_images/cat-dog-test.svg)
训练集由真实照片组成，而测试集只包含卡通图片。 假设在一个与测试集的特征有着本质不同的数据集上进行训练， 如果没有方法来适应新的领域，可能会有麻烦

2. 标签偏移
标签偏移（label shift）描述了与协变量偏移相反的问题。 这里我们假设标签边缘概率可以改变， 但是类别条件分布在不同的领域之间保持不变。 当我们认为导致时，标签偏移是一个合理的假设。 例如，预测患者的疾病，我们可能根据症状来判断， 即使疾病的相对流行率随着时间的推移而变化。 标签偏移在这里是恰当的假设，因为疾病会引起症状。 在另一些情况下，标签偏移和协变量偏移假设可以同时成立。 例如，当标签是确定的，即使导致，协变量偏移假设也会得到满足。 有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。 这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象， 而不是像输入（通常是高维的）对象。

3. 概念偏移
我们也可能会遇到概念偏移（concept shift）： 当标签的定义发生变化时，就会出现这种问题。 这听起来很奇怪——一只猫就是一只猫，不是吗？ 然而，其他类别会随着不同时间的用法而发生变化。 精神疾病的诊断标准、所谓的时髦、以及工作头衔等等，都是概念偏移的日常映射。 